# Visual Planning

After efficient adaptation, AdaWorld can be controlled directly by raw action inputs, which enables visual planning. Please refer to the [iVideoGPT setup](https://github.com/thuml/iVideoGPT/tree/main/vp) to compile our world model and perform robot planning tasks on the [VP2](https://github.com/s-tian/vp2) benchmark. You may need to batchify the sampling, otherwise it could take days.

---

<= Previous: [[World Model Adaptation](https://github.com/Little-Podi/AdaWorld/blob/main/docs/ADAPTATION.md)]

=> Next: [[Trouble Shooting](https://github.com/Little-Podi/AdaWorld/blob/main/docs/ISSUES.md)]