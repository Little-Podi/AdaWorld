model:
  base_learning_rate: 5.e-5
  target: vwm.models.diffusion.DiffusionEngine
  params:
    use_ema: true
    input_key: img_seq
    scale_factor: 0.18215
    disable_first_stage_autocast: true
    en_and_decode_n_samples_a_time: 1
    n_context_frames: &n_context_frames 6

    denoiser_config:
      target: vwm.modules.diffusionmodules.denoiser.Denoiser
      params:
        scaling_config:
          target: vwm.modules.diffusionmodules.denoiser_scaling.VScalingWithEDMcNoise

    network_config:
      target: vwm.modules.diffusionmodules.video_model.VideoUNet
      params:
        adm_in_channels: 544
        num_classes: sequential
        use_checkpoint: false
        in_channels: 8
        out_channels: 4
        model_channels: 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_head_channels: 64
        use_linear_in_transformer: true
        transformer_depth: 1
        context_dim: 1056
        spatial_transformer_attn_type: softmax-xformers
        extra_ff_mix_layer: true
        use_spatial_context: true
        merge_strategy: learned_with_images
        video_kernel_size: [ 3, 1, 1 ]
        n_context_frames: *n_context_frames

    conditioner_config:
      target: vwm.modules.GeneralConditioner
      params:
        emb_models:
          - input_key: cond_frames_without_noise
            is_trainable: false
            ucg_rate: 0.1
            target: vwm.modules.encoders.modules.FrozenOpenCLIPImagePredictionEmbedder
            params:
              open_clip_config:
                target: vwm.modules.encoders.modules.FrozenOpenCLIPImageEmbedder
                params:
                  freeze: true

          - input_key: cond_frames
            is_trainable: false
            ucg_rate: 0.1
            target: vwm.modules.encoders.modules.VideoPredictionEmbedderWithEncoder
            params:
              disable_encoder_autocast: true
              n_context_frames: *n_context_frames

              encoder_config:
                target: vwm.models.autoencoder.AutoencoderKLModeOnly
                params:
                  embed_dim: 4
                  monitor: val/rec_loss

                  ddconfig:
                    attn_type: vanilla-xformers
                    z_channels: 4
                    resolution: 256
                    in_channels: 3
                    out_channels: 3
                    ch: 128
                    ch_mult: [ 1, 2, 4, 4 ]
                    num_res_blocks: 2
                    attn_resolutions: [ ]
                    dropout: 0.0

                  loss_config:
                    target: torch.nn.Identity

          - input_key: raw_action
            is_trainable: true
            ucg_rate: 0.1
            target: vwm.modules.encoders.modules.ActionBook
            params:
              num_actions: 3
              action_dim: 32

          - input_key: context_len
            is_trainable: false
            ucg_rate: 0.1
            target: vwm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              output_dim: 256

          - input_key: context_aug
            is_trainable: false
            ucg_rate: 0.1
            target: vwm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              output_dim: 256

    first_stage_config:
      target: vwm.models.autoencoder.AutoencodingEngine
      params:
        loss_config:
          target: torch.nn.Identity

        regularizer_config:
          target: vwm.modules.autoencoding.regularizer.DiagonalGaussianRegularizer

        encoder_config:
          target: vwm.modules.diffusionmodules.model.Encoder
          params:
            attn_type: vanilla
            z_channels: 4
            resolution: 256
            in_channels: 3
            out_channels: 3
            ch: 128
            ch_mult: [ 1, 2, 4, 4 ]
            num_res_blocks: 2
            attn_resolutions: [ ]
            dropout: 0.0

        decoder_config:
          target: vwm.modules.autoencoding.temporal_ae.VideoDecoder
          params:
            attn_type: vanilla
            z_channels: 4
            resolution: 256
            in_channels: 3
            out_channels: 3
            ch: 128
            ch_mult: [ 1, 2, 4, 4 ]
            num_res_blocks: 2
            attn_resolutions: [ ]
            dropout: 0.0
            video_kernel_size: [ 3, 1, 1 ]

    scheduler_config:
      target: vwm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps: [ 100 ]
        cycle_lengths: [ 1000000000000 ]
        f_start: [ 1.e-6 ]
        f_max: [ 1. ]
        f_min: [ 1. ]

    loss_fn_config:
      target: vwm.modules.diffusionmodules.loss.StandardDiffusionLoss
      params:
        n_context_frames: *n_context_frames

        sigma_sampler_config:
          target: vwm.modules.diffusionmodules.sigma_sampling.EDMSampling
          params:
            p_mean: 1.0
            p_std: 1.6

        loss_weighting_config:
          target: vwm.modules.diffusionmodules.loss_weighting.VWeighting

    sampler_config:
      target: vwm.modules.diffusionmodules.sampling.EulerEDMSampler
      params:
        num_steps: 5
        n_context_frames: *n_context_frames

        discretization_config:
          target: vwm.modules.diffusionmodules.discretizer.EDMDiscretization
          params:
            sigma_max: 700.0

        guider_config:
          target: vwm.modules.diffusionmodules.guiders.VanillaCFG
          params:
            scale: 1.25

data:
  target: vwm.data.dataset.VideoDataSampler
  params:
    data_root: ../data
    env_source: habitat
    batch_size: 4
    num_workers: 16
    resolution: 256
    n_context_frames: *n_context_frames
    samples_per_epoch: 6400

lightning:
  callbacks:
    image_logger:
      target: train.ImageLogger
      params:
        disabled: false
        enable_autocast: false
        batch_frequency: 100
        increase_log_steps: true
        log_first_step: false
        n_context_frames: *n_context_frames

  modelcheckpoint:
    params:
      every_n_epochs: 1

  trainer:
    devices: 0,1
    benchmark: true
    num_sanity_val_steps: 0
    accumulate_grad_batches: 1
    max_epochs: 5
    strategy: deepspeed_stage_2
    gradient_clip_val: 0.3